{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from functools import partial\n",
    "import uproot\n",
    "\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from coffea.lookup_tools import extractor, dense_lookup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker,colors\n",
    "\n",
    "import numba\n",
    "\n",
    "from utils.plotting import plotWithRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.crossSections import *\n",
    "from utils.efficiencies import getMuSF, getEleSF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('utils/taggingEfficienciesDenseLookup.pkl','rb') as _file:\n",
    "    taggingEffLookup = pickle.load(_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muSFFileList = [{'id'   : (\"ScaleFactors/MuEGammaScaleFactors/mu2016/EfficienciesStudies_2016_legacy_rereco_rootfiles_RunBCDEF_SF_ID.root\", \"NUM_TightID_DEN_genTracks_eta_pt\"),\n",
    "                 'iso'   : (\"ScaleFactors/MuEGammaScaleFactors/mu2016/EfficienciesStudies_2016_legacy_rereco_rootfiles_RunBCDEF_SF_ISO.root\", \"NUM_TightRelIso_DEN_TightIDandIPCut_eta_pt\"),\n",
    "                 'trig'  : (\"ScaleFactors/MuEGammaScaleFactors/mu2016/EfficienciesStudies_2016_trigger_EfficienciesAndSF_RunBtoF.root\", \"IsoMu24_OR_IsoTkMu24_PtEtaBins/abseta_pt_ratio\"),\n",
    "                 'scale' : 19.656062760/35.882515396},\n",
    "                {'id'     : (\"ScaleFactors/MuEGammaScaleFactors/mu2016/EfficienciesStudies_2016_legacy_rereco_rootfiles_RunGH_SF_ID.root\", \"NUM_TightID_DEN_genTracks_eta_pt\"),\n",
    "                 'iso'   : (\"ScaleFactors/MuEGammaScaleFactors/mu2016/EfficienciesStudies_2016_legacy_rereco_rootfiles_RunGH_SF_ISO.root\", \"NUM_TightRelIso_DEN_TightIDandIPCut_eta_pt\"),\n",
    "                 'trig'  : (\"ScaleFactors/MuEGammaScaleFactors/mu2016/EfficienciesStudies_2016_trigger_EfficienciesAndSF_RunGtoH.root\", \"IsoMu24_OR_IsoTkMu24_PtEtaBins/abseta_pt_ratio\"),\n",
    "                 'scale' : 16.226452636/35.882515396}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fileSet_2016 import fileSet_2016 as fileset\n",
    "\n",
    "\n",
    "###In skim, look at event count histograms to find total mcEventYields\n",
    "# mcEventYields = {}\n",
    "# for sample,fNameList in fileset.items():\n",
    "#     _hist = uproot.open(fNameList[0])['hEvents'].values\n",
    "#     for fName in fNameList[1:]:\n",
    "#         _hist += uproot.open(fName)['hEvents'].values\n",
    "#     mcEventYields[sample] = _hist[2] - _hist[0]\n",
    "\n",
    "# print (mcEventYields)\n",
    "\n",
    "mcEventYields = {'DYjetsM10to50_2016': 35114961.0, 'DYjetsM50_2016': 146280395.0, 'GJets_HT40To100_2016': 9326139.0, 'GJets_HT100To200_2016': 10104155.0, 'GJets_HT200To400_2016': 20527506.0, 'GJets_HT400To600_2016': 5060070.0, 'GJets_HT600ToInf_2016': 5080857.0, 'QCD_Pt20to30_Ele_2016': 9241500.0, 'QCD_Pt30to50_Ele_2016': 11508842.0, 'QCD_Pt50to80_Ele_2016': 45789059.0, 'QCD_Pt80to120_Ele_2016': 77800204.0, 'QCD_Pt120to170_Ele_2016': 75367655.0, 'QCD_Pt170to300_Ele_2016': 11105095.0, 'QCD_Pt300toInf_Ele_2016': 7090318.0, 'QCD_Pt20to30_Mu_2016': 31878740.0, 'QCD_Pt30to50_Mu_2016': 29936360.0, 'QCD_Pt50to80_Mu_2016': 19662175.0, 'QCD_Pt80to120_Mu_2016': 23686772.0, 'QCD_Pt120to170_Mu_2016': 7897731.0, 'QCD_Pt170to300_Mu_2016': 17350231.0, 'QCD_Pt300to470_Mu_2016': 49005976.0, 'QCD_Pt470to600_Mu_2016': 19489276.0, 'QCD_Pt600to800_Mu_2016': 9981311.0, 'QCD_Pt800to1000_Mu_2016': 19940747.0, 'QCD_Pt1000toInf_Mu_2016': 13608903.0, 'ST_s_channel_2016': 6137801.0, 'ST_tW_channel_2016': 4945734.0, 'ST_tbarW_channel_2016': 4942374.0, 'ST_tbar_channel_2016': 17780700.0, 'ST_t_channel_2016': 31848000.0, 'TTGamma_Dilepton_2016': 5728644.0, 'TTGamma_Hadronic_2016': 5635346.0, 'TTGamma_SingleLept_2016': 10991612.0, 'TTWtoLNu_2016': 2716249.0, 'TTWtoQQ_2016': 430310.0, 'TTZtoLL_2016': 6420825.0, 'TTbarPowheg_Dilepton_2016': 67339946.0, 'TTbarPowheg_Hadronic_2016': 67963984.0, 'TTbarPowheg_Semilept_2016': 106438920.0, 'W1jets_2016': 45283121.0, 'W2jets_2016': 60438768.0, 'W3jets_2016': 59300029.0, 'W4jets_2016': 29941394.0, 'WGamma_01J_5f_2016': 6103817.0, 'ZGamma_01J_5f_lowMass_2016': 9696539.0, 'WW_2016': 7982180.0, 'WZ_2016': 3997571.0, 'ZZ_2016': 1988098.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def maxHistoryPDGID(idxList_contents, idxList_starts, idxList_stops, pdgID_contents, pdgID_starts, pdgID_stops, motherIdx_contents, motherIdx_starts, motherIdx_stops):\n",
    "    maxPDGID_array = np.ones(len(idxList_starts),np.int32)*-1\n",
    "    for i in range(len(idxList_starts)):\n",
    "        if idxList_starts[i]==idxList_stops[i]:\n",
    "            continue\n",
    "            \n",
    "        idxList = idxList_contents[idxList_starts[i]:idxList_stops[i]]\n",
    "        pdgID = pdgID_contents[pdgID_starts[i]:pdgID_stops[i]]\n",
    "        motherIdx = motherIdx_contents[motherIdx_starts[i]:motherIdx_stops[i]]\n",
    "    \n",
    "        idx = idxList[0]\n",
    "        maxPDGID = -1\n",
    "        while idx>-1:\n",
    "            pdg = pdgID[idx]\n",
    "            maxPDGID = max(maxPDGID, abs(pdg))\n",
    "            idx = motherIdx[idx]\n",
    "        maxPDGID_array[i] = maxPDGID\n",
    "    return maxPDGID_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at ProcessorABC to see the expected methods and what they are supposed to do\n",
    "class TTGammaProcessor(processor.ProcessorABC):\n",
    "#     def __init__(self, runNum = -1, eventNum = -1):\n",
    "    def __init__(self, runNum = -1, eventNum = -1, mcEventYields = None):\n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Dataset\")\n",
    "        lep_axis = hist.Bin(\"lepFlavor\", r\"ElectronOrMuon\", 3, -1.5, 1.5)\n",
    "        \n",
    "        m3_axis = hist.Bin(\"M3\", r\"$M_3$ [GeV]\", 200, 0., 1000)\n",
    "        mass_axis = hist.Bin(\"mass\", r\"$m_{\\ell\\gamm}$ [GeV]\", 400, 0., 400)\n",
    "        pt_axis = hist.Bin(\"pt\", r\"$p_{T}$ [GeV]\", 200, 0., 1000)\n",
    "        eta_axis = hist.Bin(\"eta\", r\"$\\eta_{\\gamma}$\", 300, -1.5, 1.5)\n",
    "        chIso_axis = hist.Bin(\"chIso\", r\"Charged Hadron Isolation\", np.arange(-0.1,20.001,.05))\n",
    "\n",
    "        ## Define axis to keep track of photon category\n",
    "        phoCategory_axis = hist.Bin(\"category\", r\"Photon Category\", [1,2,3,4,5])\n",
    "        phoCategory_axis.identifiers()[0].label = \"Genuine Photon\"    \n",
    "        phoCategory_axis.identifiers()[1].label = \"Misidentified Electron\"    \n",
    "        phoCategory_axis.identifiers()[2].label = \"Hadronic Photon\"    \n",
    "        phoCategory_axis.identifiers()[3].label = \"Hadronic Fake\"    \n",
    "        \n",
    "        ###\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            ##photon histograms\n",
    "            'photon_pt': hist.Hist(\"Counts\", dataset_axis, pt_axis, phoCategory_axis, lep_axis),\n",
    "            'photon_eta': hist.Hist(\"Counts\", dataset_axis, eta_axis, phoCategory_axis, lep_axis),\n",
    "            'photon_chIso': hist.Hist(\"Counts\", dataset_axis, chIso_axis, phoCategory_axis, lep_axis),\n",
    "            'photon_chIsoSideband': hist.Hist(\"Counts\", dataset_axis, chIso_axis, phoCategory_axis, lep_axis),\n",
    "            'photon_lepton_mass': hist.Hist(\"Counts\", dataset_axis, mass_axis, phoCategory_axis, lep_axis),\n",
    "            'photon_lepton_mass_3j0t': hist.Hist(\"Counts\", dataset_axis, mass_axis, phoCategory_axis, lep_axis),\n",
    "            'M3'      : hist.Hist(\"Counts\", dataset_axis, m3_axis, phoCategory_axis, lep_axis),\n",
    "            'M3Presel': hist.Hist(\"Counts\", dataset_axis, m3_axis, lep_axis),\n",
    "            'EventCount':processor.value_accumulator(int)\n",
    "        })\n",
    "\n",
    "        self.eventNum = eventNum\n",
    "        self.runNum = runNum\n",
    "\n",
    "        ext = extractor()\n",
    "        ext.add_weight_sets([\"btag2016 * ScaleFactors/Btag/DeepCSV_2016LegacySF_V1.btag.csv\"])\n",
    "        ext.finalize()\n",
    "        self.evaluator = ext.make_evaluator()\n",
    "        \n",
    "        ele_id_file = uproot.open('ScaleFactors/MuEGammaScaleFactors/ele2016/2016LegacyReReco_ElectronTight_Fall17V2.root')\n",
    "        self.ele_id_sf = dense_lookup.dense_lookup(ele_id_file[\"EGamma_SF2D\"].values, ele_id_file[\"EGamma_SF2D\"].edges)\n",
    "        self.ele_id_err = dense_lookup.dense_lookup(ele_id_file[\"EGamma_SF2D\"].variances**0.5, ele_id_file[\"EGamma_SF2D\"].edges)\n",
    "\n",
    "        ele_reco_file = uproot.open('ScaleFactors/MuEGammaScaleFactors/ele2016/egammaEffi.txt_EGM2D_runBCDEF_passingRECO.root')\n",
    "        self.ele_reco_sf = dense_lookup.dense_lookup(ele_reco_file[\"EGamma_SF2D\"].values, ele_reco_file[\"EGamma_SF2D\"].edges)\n",
    "        self.ele_reco_err = dense_lookup.dense_lookup(ele_reco_file[\"EGamma_SF2D\"].variances**.5, ele_reco_file[\"EGamma_SF2D\"].edges)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        mu_id_vals = 0\n",
    "        mu_id_err = 0\n",
    "        mu_iso_vals = 0\n",
    "        mu_iso_err = 0\n",
    "        mu_trig_vals = 0\n",
    "        mu_trig_err = 0\n",
    "\n",
    "        for scaleFactors in muSFFileList:\n",
    "            id_file = uproot.open(scaleFactors['id'][0])\n",
    "            iso_file = uproot.open(scaleFactors['iso'][0])\n",
    "            trig_file = uproot.open(scaleFactors['trig'][0])\n",
    "\n",
    "            mu_id_vals += id_file[scaleFactors['id'][1]].values * scaleFactors['scale']\n",
    "            mu_id_err += id_file[scaleFactors['id'][1]].variances**0.5 * scaleFactors['scale']\n",
    "            mu_id_edges = id_file[scaleFactors['id'][1]].edges\n",
    "\n",
    "            mu_iso_vals += iso_file[scaleFactors['iso'][1]].values * scaleFactors['scale']\n",
    "            mu_iso_err += iso_file[scaleFactors['iso'][1]].variances**0.5 * scaleFactors['scale']\n",
    "            mu_iso_edges = iso_file[scaleFactors['iso'][1]].edges\n",
    "\n",
    "            mu_trig_vals += trig_file[scaleFactors['trig'][1]].values * scaleFactors['scale']\n",
    "            mu_trig_err += trig_file[scaleFactors['trig'][1]].variances**0.5 * scaleFactors['scale']\n",
    "            mu_trig_edges = trig_file[scaleFactors['trig'][1]].edges\n",
    "\n",
    "        self.mu_id_sf = dense_lookup.dense_lookup(mu_id_vals, mu_id_edges)\n",
    "        self.mu_id_err = dense_lookup.dense_lookup(mu_id_err, mu_id_edges)\n",
    "        self.mu_iso_sf = dense_lookup.dense_lookup(mu_iso_vals, mu_iso_edges)\n",
    "        self.mu_iso_err = dense_lookup.dense_lookup(mu_iso_err, mu_iso_edges)\n",
    "        self.mu_trig_sf = dense_lookup.dense_lookup(mu_trig_vals, mu_trig_edges)\n",
    "        self.mu_trig_err = dense_lookup.dense_lookup(mu_trig_err, mu_trig_edges)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        output = self.accumulator.identity()\n",
    "\n",
    "        datasetFull = df['dataset']\n",
    "        dataset=datasetFull.replace('_2016','')\n",
    "\n",
    "        isData = 'Data' in dataset\n",
    "        \n",
    "        year=2016\n",
    "        yearStr=\"2016\"\n",
    "        muTrigger = df['HLT_IsoMu24'] | df['HLT_IsoTkMu24']\n",
    "        eleTrigger = df['HLT_Ele27_WPTight_Gsf']\n",
    "        photonBitMapName = 'Photon_cutBased'\n",
    "#        btagSF = 'test_DeepCSV_2016LegacySF_V1.btag.csv'\n",
    "\n",
    "        \n",
    "        filters = (df['Flag_goodVertices'] &\n",
    "                   df['Flag_globalSuperTightHalo2016Filter'] &\n",
    "                   df['Flag_HBHENoiseFilter'] &\n",
    "                   df['Flag_HBHENoiseIsoFilter'] &\n",
    "                   df['Flag_EcalDeadCellTriggerPrimitiveFilter'] &\n",
    "                   df['Flag_BadPFMuonFilter'] \n",
    "                  )\n",
    "        if year > 2016:\n",
    "            filters = (filters & \n",
    "                       df['Flag_ecalBadCalibFilterV2']\n",
    "                      )\n",
    "        \n",
    "        \n",
    "        \n",
    "        muons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nMuon'],\n",
    "            pt=df['Muon_pt'],\n",
    "            eta=df['Muon_eta'],\n",
    "            phi=df['Muon_phi'],\n",
    "            mass=df['Muon_mass'],\n",
    "            charge=df['Muon_charge'],\n",
    "            relIso=df['Muon_pfRelIso04_all'],\n",
    "            tightId=df['Muon_tightId'],\n",
    "            isPFcand=df['Muon_isPFcand'],\n",
    "            isTracker=df['Muon_isTracker'],\n",
    "            isGlobal=df['Muon_isGlobal'],           \n",
    "        )\n",
    "        \n",
    "        electrons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nElectron'],\n",
    "            pt=df['Electron_pt'],\n",
    "            eta=df['Electron_eta'],\n",
    "            phi=df['Electron_phi'],\n",
    "            mass=df['Electron_mass'],\n",
    "            charge=df['Electron_charge'],\n",
    "            cutBased=df['Electron_cutBased'],\n",
    "            d0=df['Electron_dxy'],\n",
    "            dz=df['Electron_dz'],\n",
    "        )\n",
    "\n",
    "        jets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nJet'],\n",
    "            pt=df['Jet_pt'],\n",
    "            eta=df['Jet_eta'],\n",
    "            phi=df['Jet_phi'],\n",
    "            mass=df['Jet_mass'],\n",
    "            jetId=df['Jet_jetId'],\n",
    "            btag=df['Jet_btagDeepB'],\n",
    "            hadFlav=df['Jet_hadronFlavour'] if not isData else np.ones_like(df['Jet_jetId']),\n",
    "            genIdx=df['Jet_genJetIdx'] if not isData else np.ones_like(df['Jet_jetId']),\n",
    "        )\n",
    "\n",
    "        photons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nPhoton'],\n",
    "            pt=df['Photon_pt'],\n",
    "            eta=df['Photon_eta'],\n",
    "            phi=df['Photon_phi'],\n",
    "            mass=np.zeros_like(df['Photon_pt']),\n",
    "            isEE=df['Photon_isScEtaEE'],\n",
    "            isEB=df['Photon_isScEtaEB'],\n",
    "            photonId=df[photonBitMapName],\n",
    "            passEleVeto=df['Photon_electronVeto'],\n",
    "            pixelSeed=df['Photon_pixelSeed'],\n",
    "            sieie=df['Photon_sieie'],\n",
    "            chIso=df['Photon_pfRelIso03_chg']*df['Photon_pt'],\n",
    "            vidCuts=df['Photon_vidNestedWPBitmap'],\n",
    "            genFlav=df['Photon_genPartFlav'] if not isData else np.ones_like(df['Photon_electronVeto']),\n",
    "            genIdx=df['Photon_genPartIdx'] if not isData else np.ones_like(df['Photon_electronVeto']),\n",
    "        )\n",
    "        if not isData:\n",
    "            genPart = JaggedCandidateArray.candidatesfromcounts(\n",
    "                df['nGenPart'],\n",
    "                pt=df['GenPart_pt'],\n",
    "                eta=df['GenPart_eta'],\n",
    "                phi=df['GenPart_phi'],\n",
    "                mass=df['GenPart_mass'],\n",
    "                pdgid=df['GenPart_pdgId'],\n",
    "                motherIdx=df['GenPart_genPartIdxMother'],\n",
    "                status=df['GenPart_status'],\n",
    "                statusFlags=df['GenPart_statusFlags'],\n",
    "            )\n",
    "\n",
    "            genmotherIdx = genPart.motherIdx\n",
    "            genpdgid = genPart.pdgid\n",
    "\n",
    "        ## TTbar vs TTGamma Overlap Removal (work in progress, still buggy)\n",
    "        if 'TTbar' in dataset:\n",
    "            overlapPhoSelect = ((genPart.pt>=10) & \n",
    "                                (abs(genPart.eta) < 5.) & \n",
    "                                (genPart.pdgid==22) & \n",
    "                                (genPart.status==1)\n",
    "                               )\n",
    "            \n",
    "            OverlapPhotons = genPart[overlapPhoSelect] \n",
    "\n",
    "            idx = OverlapPhotons.motherIdx\n",
    "            maxParent = maxHistoryPDGID(idx.content, idx.starts, idx.stops, \n",
    "                                        genpdgid.content, genpdgid.starts, genpdgid.stops, \n",
    "                                        genmotherIdx.content, genmotherIdx.starts, genmotherIdx.stops)\n",
    "            \n",
    "            isNonPrompt = (maxParent>37).any()\n",
    "\n",
    "            finalGen = genPart[((genPart.status==1)|(genPart.status==71)) & ~((abs(genPart.pdgid)==12) | (abs(genPart.pdgid)==14) | (abs(genPart.pdgid)==16))]\n",
    "\n",
    "            genPairs = OverlapPhotons['p4'].cross(finalGen['p4'],nested=True)\n",
    "            ##remove the case where the cross produce is the gen photon with itself\n",
    "            genPairs = genPairs[~(genPairs.i0==genPairs.i1)]\n",
    "\n",
    "            dRPairs = genPairs.i0.delta_r(genPairs.i1)\n",
    "            \n",
    "            isOverlap = ((dRPairs.min()>0.1) & (maxParent<37)).any()\n",
    "            passOverlapRemoval = ~isOverlap\n",
    "        else:\n",
    "            passOverlapRemoval = np.ones_like(df['event'])==1\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        muonSelectTight = ((muons.pt>30) & \n",
    "                           (abs(muons.eta)<2.4) & \n",
    "                           (muons.tightId) & \n",
    "                           (muons.relIso < 0.15)\n",
    "                          )\n",
    "        \n",
    "        muonSelectLoose = ((muons.pt>15) & \n",
    "                           (abs(muons.eta)<2.4) & \n",
    "                           ((muons.isPFcand) & (muons.isTracker | muons.isGlobal)) & \n",
    "                           (muons.relIso < 0.25) &\n",
    "                           np.invert(muonSelectTight)\n",
    "                          )\n",
    "\n",
    "        eleEtaGap = (abs(electrons.eta) < 1.4442) | (abs(electrons.eta) > 1.566)\n",
    "        elePassD0 = ((abs(electrons.eta) < 1.479) & (abs(electrons.d0) < 0.05) |\n",
    "                     (abs(electrons.eta) > 1.479)  & (abs(electrons.d0) < 0.1)\n",
    "                    )\n",
    "        elePassDZ = ((abs(electrons.eta) < 1.479) & (abs(electrons.dz) < 0.1) |\n",
    "                     (abs(electrons.eta) > 1.479)  & (abs(electrons.dz) < 0.2)\n",
    "                    )\n",
    "\n",
    "        \n",
    "        \n",
    "        electronSelectTight = ((electrons.pt>35) & \n",
    "                               (abs(electrons.eta)<2.1) & \n",
    "                               eleEtaGap &      \n",
    "                               (electrons.cutBased>=4) &\n",
    "                               elePassD0 & \n",
    "                               elePassDZ\n",
    "                              )\n",
    "\n",
    "        electronSelectLoose = ((electrons.pt>15) & \n",
    "                               (abs(electrons.eta)<2.4) & \n",
    "                               eleEtaGap &      \n",
    "                               (electrons.cutBased>=1) &\n",
    "                               elePassD0 & \n",
    "                               elePassDZ & \n",
    "                               np.invert(electronSelectTight)\n",
    "                              )\n",
    "        \n",
    "        tightMuon = muons[muonSelectTight]\n",
    "        looseMuon = muons[muonSelectLoose]\n",
    "        \n",
    "        tightElectron = electrons[electronSelectTight]\n",
    "        looseElectron = electrons[electronSelectLoose]\n",
    "\n",
    "\n",
    "        \n",
    "        oneMuon = (tightMuon.counts == 1)\n",
    "        muVeto = (tightMuon.counts == 0)\n",
    "        oneEle = (tightElectron.counts == 1)\n",
    "        eleVeto = (tightElectron.counts == 0)\n",
    "        looseMuonSel = (looseMuon.counts == 0)\n",
    "        looseElectronSel = (looseElectron.counts == 0)\n",
    "\n",
    "        \n",
    "        #### Calculate deltaR between photon and nearest muon\n",
    "        ####### make combination pairs\n",
    "        phoMu = photons['p4'].cross(tightMuon['p4'],nested=True)\n",
    "        \n",
    "        ####### check delta R of each combination, if min is >0.1 it is okay, or if there are no tight muons it passes\n",
    "        dRphomu = (phoMu.i0.delta_r(phoMu.i1)>0.4).all() | (tightMuon.counts==0)\n",
    "        phoEle = photons['p4'].cross(tightElectron['p4'],nested=True)\n",
    "        dRphoele = ((phoEle.i0.delta_r(phoEle.i1)).min()>0.4) | (tightElectron.counts==0)\n",
    "        \n",
    "        #photon selection (no ID requirement used here)\n",
    "        photonSelect = ((photons.pt>20) & \n",
    "                        (abs(photons.eta) < 1.4442) &\n",
    "                        (photons.isEE | photons.isEB) &\n",
    "                        (photons.passEleVeto) & \n",
    "                        np.invert(photons.pixelSeed) & \n",
    "                        dRphomu & dRphoele\n",
    "                       )\n",
    "        \n",
    "        \n",
    "        #split out the ID requirement, enabling Iso and SIEIE to be inverted for control regions\n",
    "        photonID = photons.photonId >= 2\n",
    "\n",
    "        #parse VID cuts, define loose photons (not used yet)\n",
    "        photon_MinPtCut = (photons.vidCuts>>0 & 3)>=2 \n",
    "        photon_PhoSCEtaMultiRangeCut = (photons.vidCuts>>2 & 3)>=2 \n",
    "        photon_PhoSingleTowerHadOverEmCut = (photons.vidCuts>>4 & 3)>=2  \n",
    "        photon_PhoFull5x5SigmaIEtaIEtaCut = (photons.vidCuts>>6 & 3)>=2  \n",
    "        photon_ChIsoCut = (photons.vidCuts>>8 & 3)>=2  \n",
    "        photon_NeuIsoCut = (photons.vidCuts>>10 & 3)>=2  \n",
    "        photon_PhoIsoCut = (photons.vidCuts>>12 & 3)>=2  \n",
    "        \n",
    "        photonID_NoChIsoSIEIE = (photon_MinPtCut & \n",
    "                                 photon_PhoSCEtaMultiRangeCut & \n",
    "                                 photon_PhoSingleTowerHadOverEmCut & \n",
    "                                 photon_PhoFull5x5SigmaIEtaIEtaCut & \n",
    "                                 photon_NeuIsoCut & \n",
    "                                 photon_PhoIsoCut)\n",
    "\n",
    "        \n",
    "        tightPhotons = photons[photonSelect & photonID]\n",
    "        loosePhotons = photons[photonSelect & photonID_NoChIsoSIEIE & photon_PhoFull5x5SigmaIEtaIEtaCut]\n",
    "        loosePhotonsSideband = photons[photonSelect & photonID_NoChIsoSIEIE & (photons.sieie>0.012)]\n",
    "        \n",
    "        ##medium jet ID cut\n",
    "        jetIDbit = 1\n",
    "        if year>2016: jetIDbit=2\n",
    "\n",
    "        ##check dR jet,lepton & jet,photon\n",
    "        jetMu = jets['p4'].cross(tightMuon['p4'],nested=True)\n",
    "        dRjetmu = ((jetMu.i0.delta_r(jetMu.i1)).min()>0.4) | (tightMuon.counts==0)\n",
    "\n",
    "        jetEle = jets['p4'].cross(tightElectron['p4'],nested=True)\n",
    "        dRjetele = ((jetEle.i0.delta_r(jetEle.i1)).min()>0.4) | (tightElectron.counts==0)\n",
    "\n",
    "        jetPho = jets['p4'].cross(tightPhotons['p4'],nested=True)\n",
    "        dRjetpho = ((jetPho.i0.delta_r(jetPho.i1)).min()>0.1) | (tightPhotons.counts==0)\n",
    "        \n",
    "        jetSelect = ((jets.pt > 30) &\n",
    "                     (abs(jets.eta) < 2.4) &\n",
    "                     ((jets.jetId >> jetIDbit & 1)==1) &\n",
    "                     dRjetmu & dRjetele & dRjetpho                    \n",
    "                    )\n",
    "\n",
    "        tightJets = jets[jetSelect]\n",
    "        \n",
    "        bTagWP = 0.6321   #2016 DeepCSV working point\n",
    "\n",
    "        btagged = tightJets.btag>bTagWP\n",
    "\n",
    "        bJets = tightJets[btagged]\n",
    "\n",
    "        ## Define M3, mass of 3-jet pair with highest pT\n",
    "        triJet = tightJets['p4'].choose(3)\n",
    "\n",
    "        triJetPt = (triJet.i0 + triJet.i1 + triJet.i2).pt\n",
    "        triJetMass = (triJet.i0 + triJet.i1 + triJet.i2).mass\n",
    "        M3 = triJetMass[triJetPt.argmax()]\n",
    "\n",
    "\n",
    "        leadingMuon = tightMuon[::1] \n",
    "        leadingElectron = tightElectron[::1]        \n",
    "        \n",
    "        leadingPhoton = tightPhotons[:,:1]\n",
    "        leadingPhotonLoose = loosePhotons[:,:1]\n",
    "        leadingPhotonSideband = loosePhotonsSideband[:,:1]\n",
    "\n",
    "        \n",
    "#        egammaMass = (leadingElectron['p4'] + leadingPhoton['p4']).mass\n",
    "        egamma = leadingElectron['p4'].cross(leadingPhoton['p4'])\n",
    "        mugamma = leadingMuon['p4'].cross(leadingPhoton['p4'])\n",
    "        egammaMass = (egamma.i0 + egamma.i1).mass\n",
    "        mugammaMass = (mugamma.i0 + mugamma.i1).mass\n",
    "        \n",
    "        \n",
    "        \n",
    "        if not isData:\n",
    "            #### Photon categories, using genIdx branch\n",
    "            # reco photons really generated as electrons\n",
    "            isMisIDele = (leadingPhoton.genFlav==13).any()\n",
    "            matchedPho = (leadingPhoton.genFlav==1).any()\n",
    "\n",
    "            idx = leadingPhoton.genIdx\n",
    "\n",
    "            maxParent = maxHistoryPDGID(idx.content, idx.starts, idx.stops, \n",
    "                                        genpdgid.content, genpdgid.starts, genpdgid.stops, \n",
    "                                        genmotherIdx.content, genmotherIdx.starts, genmotherIdx.stops)\n",
    "\n",
    "            hadronicParent = maxParent>25\n",
    "\n",
    "            isGenPho = matchedPho & ~hadronicParent\n",
    "            isHadPho = matchedPho & hadronicParent\n",
    "            isHadFake = ~(isMisIDele | isGenPho | isHadPho) & (leadingPhoton.counts==1)\n",
    "            \n",
    "            #define integer definition for the photon category axis\n",
    "            phoCategory = 1*isGenPho + 2*isMisIDele + 3*isHadPho + 4*isHadFake\n",
    "            \n",
    "\n",
    "            isMisIDeleLoose = (leadingPhotonLoose.genFlav==13).any()\n",
    "            matchedPhoLoose = (leadingPhotonLoose.genFlav==1).any()\n",
    "\n",
    "            # look through parentage to find if any hadrons in genPhoton parent history\n",
    "            idx = leadingPhotonLoose.genIdx\n",
    "\n",
    "            maxParent = maxHistoryPDGID(idx.content, idx.starts, idx.stops, \n",
    "                                        genpdgid.content, genpdgid.starts, genpdgid.stops, \n",
    "                                        genmotherIdx.content, genmotherIdx.starts, genmotherIdx.stops)\n",
    "\n",
    "            hadronicParent = maxParent>25\n",
    "\n",
    "            isGenPhoLoose = matchedPhoLoose & ~hadronicParent\n",
    "            isHadPhoLoose = matchedPhoLoose & hadronicParent\n",
    "            isHadFakeLoose = ~(isMisIDeleLoose | isGenPhoLoose | isHadPhoLoose) & (leadingPhotonLoose.counts==1)        \n",
    "\n",
    "            #define integer definition for the photon category axis\n",
    "            phoCategoryLoose = 1*isGenPhoLoose + 2*isMisIDeleLoose + 3*isHadPhoLoose + 4*isHadFakeLoose\n",
    "\n",
    "            \n",
    "            isMisIDeleSideband = (leadingPhotonSideband.genFlav==13).any()\n",
    "            matchedPhoSideband = (leadingPhotonSideband.genFlav==1).any()\n",
    "\n",
    "            # look through parentage to find if any hadrons in genPhoton parent history\n",
    "            idx = leadingPhotonSideband.genIdx\n",
    "\n",
    "            maxParent = maxHistoryPDGID(idx.content, idx.starts, idx.stops, \n",
    "                                        genpdgid.content, genpdgid.starts, genpdgid.stops, \n",
    "                                        genmotherIdx.content, genmotherIdx.starts, genmotherIdx.stops)\n",
    "\n",
    "            hadronicParent = maxParent>25\n",
    "\n",
    "            isGenPhoSideband = matchedPhoSideband & ~hadronicParent\n",
    "            isHadPhoSideband = matchedPhoSideband & hadronicParent\n",
    "            isHadFakeSideband = ~(isMisIDeleSideband | isGenPhoSideband | isHadPhoSideband) & (leadingPhotonSideband.counts==1)        \n",
    "\n",
    "            #define integer definition for the photon category axis\n",
    "            phoCategorySideband = 1*isGenPhoSideband + 2*isMisIDeleSideband + 3*isHadPhoSideband + 4*isHadFakeSideband            \n",
    "        else:\n",
    "            phoCategory = np.ones_like(df['event'])\n",
    "            phoCategoryLoose = np.ones_like(df['event'])\n",
    "            phoCategorySideband = np.ones_like(df['event'])\n",
    "        \n",
    "                            \n",
    "        #ele_trigger = eleTrigger\n",
    "        mu_noLoose = (muTrigger & filters & passOverlapRemoval &\n",
    "                      oneMuon & eleVeto &\n",
    "                      looseMuonSel & looseElectronSel)\n",
    "        ele_noLoose = (eleTrigger & filters & passOverlapRemoval &\n",
    "                       oneEle & muVeto &\n",
    "                       looseMuonSel & looseElectronSel)\n",
    "\n",
    "        lep_noLoose = mu_noLoose| ele_noLoose\n",
    "        \n",
    "        lep_jetSel = (lep_noLoose & \n",
    "                      (tightJets.counts >= 4) & (bJets.counts >= 1)\n",
    "                     )\n",
    "        lep_zeropho = (lep_jetSel & \n",
    "                       (tightPhotons.counts == 0)\n",
    "                      )\n",
    "        lep_phosel = (lep_jetSel & \n",
    "                      (tightPhotons.counts == 1)\n",
    "                     )\n",
    "        lep_phoselLoose = (lep_jetSel & \n",
    "                           (loosePhotons.counts == 1)\n",
    "                          )\n",
    "        lep_phoselSideband = (lep_jetSel & \n",
    "                              (loosePhotonsSideband.counts == 1)\n",
    "                             )\n",
    "\n",
    "        lep_phosel_3j0t = (lep_noLoose & \n",
    "                           (tightJets.counts >= 3) & (bJets.counts ==0) &\n",
    "                           (tightPhotons.counts == 1)\n",
    "                          )\n",
    "\n",
    "#         mu_jetSel = (mu_noLoose & \n",
    "#                      (tightJets.counts >= 4) & (bJets.counts >= 1) )                     \n",
    "#         mu_phosel = (mu_jetSel & \n",
    "#                      (tightPhotons.counts == 1))\n",
    "#         mu_zeropho = (mu_jetSel & \n",
    "#                       (tightPhotons.counts == 0))\n",
    "#         mu_phoselLoose = (mu_jetSel & \n",
    "#                           (loosePhotons.counts == 1))    \n",
    "#         mu_phoselSideband = (mu_jetSel & \n",
    "#                              (loosePhotonsSideband.counts == 1))    \n",
    "        \n",
    "#         ele_jetSel = (ele_noLoose & \n",
    "#                       (tightJets.counts >= 4) & (bJets.counts >= 1) )                     \n",
    "#         ele_phosel = (ele_jetSel & \n",
    "#                       (tightPhotons.counts == 1))\n",
    "#         ele_zeropho = (ele_jetSel & \n",
    "#                        (tightPhotons.counts == 0))\n",
    "#         ele_phoselLoose = (ele_jetSel & \n",
    "#                            (loosePhotons.counts == 1))    \n",
    "#         ele_phoselSideband = (ele_jetSel & \n",
    "#                               (loosePhotonsSideband.counts == 1))    \n",
    "                            \n",
    "#         lep_jetSel = mu_jetSel | ele_jetSel\n",
    "#         lep_zeropho = mu_zeropho | ele_zeropho\n",
    "#         lep_phosel = mu_phosel | ele_phosel\n",
    "#         lep_phoselLoose = mu_phoselLoose | ele_phoselLoose\n",
    "#         lep_phoselSideband = mu_phoselSideband | ele_phoselSideband\n",
    "        \n",
    "        lepFlavor = -1*ele_noLoose + 1*mu_noLoose\n",
    "        \n",
    "\n",
    "        \n",
    "        evtWeight = np.ones_like(df['event'],dtype=np.float64)        \n",
    "        if not 'Data' in dataset:\n",
    "            nMCevents = mcEventYields[datasetFull]\n",
    "            xsec = crossSections[dataset]\n",
    "\n",
    "            evtWeight *= xsec * lumis[year] / nMCevents\n",
    "\n",
    "            #btag key name\n",
    "            #name / working Point / type / systematic / jetType\n",
    "            #  ... / 0-loose 1-medium 2-tight / comb,mujets,iterativefit / central,up,down / 0-b 1-c 2-udcsg \n",
    "            bJetSF = self.evaluator['btag%iDeepCSV_1_comb_central_0'%year](tightJets.eta, tightJets.pt, tightJets.btag)\n",
    "            bJetSF_c = self.evaluator['btag%iDeepCSV_1_comb_central_1'%year](tightJets.eta, tightJets.pt, tightJets.btag)\n",
    "            bJetSF_udcsg = self.evaluator['btag%iDeepCSV_1_incl_central_2'%year](tightJets.eta, tightJets.pt, tightJets.btag)\n",
    "\n",
    "            bJetSF.content[(tightJets.hadFlav==4).content] = bJetSF_c[tightJets.hadFlav==4].content\n",
    "            bJetSF.content[(tightJets.hadFlav==0).content] = bJetSF_udcsg[tightJets.hadFlav==0].content\n",
    "\n",
    "\n",
    "            ## mc efficiency lookup, data efficiency is eff* scale factor\n",
    "            btagEfficiencies = taggingEffLookup(datasetFull,tightJets.hadFlav,tightJets.pt,tightJets.eta)\n",
    "            btagEfficienciesData = btagEfficiencies*bJetSF\n",
    "\n",
    "            ##probability is the product of all efficiencies of tagged jets, times product of 1-eff for all untagged jets\n",
    "            ## https://twiki.cern.ch/twiki/bin/view/CMS/BTagSFMethods#1a_Event_reweighting_using_scale\n",
    "            pMC   = btagEfficiencies[btagged].prod()     * (1.-btagEfficiencies[np.invert(btagged)]).prod() \n",
    "            pData = btagEfficienciesData[btagged].prod() * (1.-btagEfficienciesData[np.invert(btagged)]).prod()\n",
    "            btagWeight = pData/pMC\n",
    "            btagWeight[pData==0]=0\n",
    "\n",
    "            evtWeight *= btagWeight\n",
    "\n",
    "            eleID = self.ele_id_sf(tightElectron.eta, tightElectron.pt)\n",
    "            eleIDerr = self.ele_id_err(tightElectron.eta, tightElectron.pt)\n",
    "            eleRECO = self.ele_reco_sf(tightElectron.eta, tightElectron.pt)\n",
    "            eleRECOerr = self.ele_reco_err(tightElectron.eta, tightElectron.pt)\n",
    "            \n",
    "            eleSF = (eleID*eleRECO).prod()\n",
    "            eleSFup = ((eleID + eleIDerr) * (eleRECO + eleRECOerr)).prod()\n",
    "            eleSFdo = ((eleID - eleIDerr) * (eleRECO - eleRECOerr)).prod()\n",
    "\n",
    "            evtWeight *= eleSF\n",
    "\n",
    "            muID = self.mu_id_sf(tightMuon.eta, tightMuon.pt)\n",
    "            muIDerr = self.mu_id_err(tightMuon.eta, tightMuon.pt)\n",
    "            muIso = self.mu_iso_sf(tightMuon.eta, tightMuon.pt)\n",
    "            muIsoerr = self.mu_iso_err(tightMuon.eta, tightMuon.pt)\n",
    "            muTrig = self.mu_iso_sf(abs(tightMuon.eta), tightMuon.pt)\n",
    "            muTrigerr = self.mu_iso_err(abs(tightMuon.eta), tightMuon.pt)\n",
    "            \n",
    "            muSF = (muID*muIso*muTrig).prod()\n",
    "            muSF_up = ((muID + muIDerr) * (muIso + muIsoerr) * (muTrig + muTrigerr)).prod()\n",
    "            muSF_down = ((muID - muIDerr) * (muIso - muIsoerr) * (muTrig - muTrigerr)).prod()\n",
    "\n",
    "            evtWeight *= muSF\n",
    "        \n",
    "        output['photon_pt'].fill(dataset=dataset,\n",
    "                                 pt=tightPhotons.p4.pt[:,:1][lep_phosel].flatten(),\n",
    "                                 category=phoCategory[lep_phosel].flatten(),\n",
    "                                 lepFlavor=lepFlavor[lep_phosel],\n",
    "                                 weight=evtWeight[lep_phosel].flatten())\n",
    "\n",
    "        output['photon_eta'].fill(dataset=dataset,\n",
    "                                  eta=tightPhotons.eta[:,:1][lep_phosel].flatten(),\n",
    "                                  category=phoCategory[lep_phosel].flatten(),\n",
    "                                  lepFlavor=lepFlavor[lep_phosel],\n",
    "                                  weight=evtWeight[lep_phosel].flatten())\n",
    "\n",
    "        output['photon_chIsoSideband'].fill(dataset=dataset,\n",
    "                                            chIso=loosePhotonsSideband.chIso[:,:1][lep_phoselSideband].flatten(),\n",
    "                                            category=phoCategorySideband[lep_phoselSideband].flatten(),\n",
    "                                            lepFlavor=lepFlavor[lep_phoselSideband],\n",
    "                                            weight=evtWeight[lep_phoselSideband].flatten())\n",
    "\n",
    "        output['photon_chIso'].fill(dataset=dataset,\n",
    "                                    chIso=loosePhotons.chIso[:,:1][lep_phoselLoose].flatten(),\n",
    "                                    category=phoCategoryLoose[lep_phoselLoose].flatten(),\n",
    "                                    lepFlavor=lepFlavor[lep_phoselLoose],\n",
    "                                    weight=evtWeight[lep_phoselLoose].flatten())\n",
    "\n",
    "        output['photon_lepton_mass'].fill(dataset=dataset,\n",
    "                                          mass=egammaMass[lep_phosel & ele_noLoose].flatten(),\n",
    "                                          category=phoCategory[lep_phosel & ele_noLoose].flatten(),\n",
    "                                          lepFlavor=lepFlavor[lep_phosel & ele_noLoose],\n",
    "                                          weight=evtWeight[lep_phosel & ele_noLoose].flatten())\n",
    "        output['photon_lepton_mass'].fill(dataset=dataset,\n",
    "                                          mass=mugammaMass[lep_phosel & mu_noLoose].flatten(),\n",
    "                                          category=phoCategory[lep_phosel & mu_noLoose].flatten(),\n",
    "                                          lepFlavor=lepFlavor[lep_phosel & mu_noLoose],\n",
    "                                          weight=evtWeight[lep_phosel & mu_noLoose].flatten())\n",
    "\n",
    "        output['photon_lepton_mass_3j0t'].fill(dataset=dataset,\n",
    "                                               mass=egammaMass[lep_phosel_3j0t & ele_noLoose].flatten(),\n",
    "                                               category=phoCategory[lep_phosel_3j0t & ele_noLoose].flatten(),\n",
    "                                               lepFlavor=lepFlavor[lep_phosel_3j0t & ele_noLoose],\n",
    "                                               weight=evtWeight[lep_phosel_3j0t & ele_noLoose].flatten())\n",
    "        output['photon_lepton_mass_3j0t'].fill(dataset=dataset,\n",
    "                                               mass=mugammaMass[lep_phosel_3j0t & mu_noLoose].flatten(),\n",
    "                                               category=phoCategory[lep_phosel_3j0t & mu_noLoose].flatten(),\n",
    "                                               lepFlavor=lepFlavor[lep_phosel_3j0t & mu_noLoose],\n",
    "                                               weight=evtWeight[lep_phosel_3j0t & mu_noLoose].flatten())\n",
    "        \n",
    "        \n",
    "        output['M3'].fill(dataset=dataset,\n",
    "                          M3=M3[lep_phosel].flatten(),\n",
    "                          category=phoCategoryLoose[lep_phosel].flatten(),\n",
    "                          lepFlavor=lepFlavor[lep_phosel],\n",
    "                          weight=evtWeight[lep_phosel].flatten())\n",
    "\n",
    "        output['M3Presel'].fill(dataset=dataset,\n",
    "                          M3=M3[lep_zeropho].flatten(),\n",
    "                          lepFlavor=lepFlavor[lep_zeropho],\n",
    "                          weight=evtWeight[lep_zeropho].flatten())                            \n",
    "        \n",
    "        output['EventCount'] = len(df['event'])\n",
    "\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filesetTemp = {k:fileset[k] for k in fileset if 'TTGamma' in k}\n",
    "tstart = time.time()\n",
    "output = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=TTGammaProcessor(mcEventYields=mcEventYields),\n",
    "                                  executor=processor.futures_executor,\n",
    "                                  executor_args={'workers': 4, 'flatten': True},\n",
    "#                                   chunksize=25000,\n",
    "#                                   maxchunks=0\n",
    "                                 )\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print(\"Total time: %.1f seconds\"%elapsed)\n",
    "print(\"Total rate: %.1f events / second\"%(output['EventCount'].value/elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fileSet_2016 import fileSet_Data_2016\n",
    "\n",
    "tstart = time.time()\n",
    "outputData = processor.run_uproot_job(fileSet_Data_2016,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=TTGammaProcessor(mcEventYields=mcEventYields),\n",
    "                                  executor=processor.futures_executor,\n",
    "                                  executor_args={'workers': 4, 'flatten': True},\n",
    "#                                   chunksize=5000,\n",
    "#                                   maxchunks=0                                                                                              \n",
    "                                 )\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print(\"Total time: %.1f seconds\"%elapsed)\n",
    "print(\"Total rate: %.1f events / second\"%(outputData['EventCount'].value/elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('histogramOutputMC.pkl','wb') as _file:\n",
    "    pickle.dump(output,_file)\n",
    "\n",
    "with open('histogramOutputData.pkl','wb') as _file:\n",
    "    pickle.dump(outputData,_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
