{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import coffea.processor as processor\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "import hist # coffea.hist is deprecated as of Jan 2023!\n",
    "\n",
    "# this avoids some warnings due to using older NanoAOD ntuples\n",
    "NanoAODSchema.warn_missing_crossrefs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below introduces some basic concepts for writing code using Coffea.  \n",
    "\n",
    "There are three primary pieces to the Coffea code:  \n",
    "1. The *processor*, which contains all of the analysis cuts and fills the histogram in the _process_ function. \n",
    "2. The second cell defines the files we want to run over and then runs the code using run_uproot_job. \n",
    "3. After we run the processor, we can then plot any of the histograms we have generated.\n",
    "\n",
    "To test any changes you make to the histograms, you will have to rerun each of the three cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/TTGamma_1l.root\"\n",
    "events = NanoEventsFactory.from_root(fname, schemaclass=NanoAODSchema).events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HLT',\n",
       " 'Flag',\n",
       " 'Muon',\n",
       " 'luminosityBlock',\n",
       " 'LHEPdfWeight',\n",
       " 'event',\n",
       " 'GenJet',\n",
       " 'Jet',\n",
       " 'GenMET',\n",
       " 'run',\n",
       " 'Generator',\n",
       " 'LHEWeight',\n",
       " 'PSWeight',\n",
       " 'Pileup',\n",
       " 'LHEScaleWeight',\n",
       " 'Electron',\n",
       " 'GenPart',\n",
       " 'MET',\n",
       " 'fixedGridRhoFastjetAll',\n",
       " 'Photon']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dxy', 'dz', 'eta', 'mass', 'phi', 'pt', 'charge', 'cutBased']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.Electron.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTGammaCutflow(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        ### This function is where the histograms are defined and any other initialization happens\n",
    "        \n",
    "        ### Muon pt\n",
    "        \n",
    "        #Declare an axis for the muon pt\n",
    "        muon_pt_axis = hist.axis.Regular(40, 0, 200, name=\"pt\", label=\"Muon $p_{T}$ [GeV]\")\n",
    "        ele_pt_axis  = hist.axis.Regular(40, 0, 200, name=\"pt\", label=\"Electron $p_{T}$ [GeV]\")\n",
    "\n",
    "        #Define a dictionary storing all of the histograms and counters \n",
    "        #that we will fill later in the process function\n",
    "        self.make_output = lambda: {\n",
    "            'muon_pt': hist.Hist(muon_pt_axis),\n",
    "            ######\n",
    "            ### Step 1. Add a histogram for the electron pt\n",
    "            ######\n",
    "            'ele_pt' : hist.Hist(ele_pt_axis),\n",
    "        }\n",
    "        \n",
    "        ######\n",
    "\n",
    "    def process(self, events):\n",
    "        ### The process function is where most of the work happens. As we'll see below, this is\n",
    "        ### where the main analysis work happens (object cuts, event selections, filling histograms). \n",
    "        \n",
    "        ## This gets us the dictionary of histograms we defined in init\n",
    "        output = self.make_output()\n",
    "\n",
    "        ## To access variables from the ntuples, use the \"events\" object\n",
    "        ## The dataset name is part of events.metadata\n",
    "        dataset = events.metadata['dataset']\n",
    "        \n",
    "        ## The coffea NanoEventSchema packages all muon variables (columns) into the events.Muon object\n",
    "        ## Each variable can be accessed using muons.key_name\n",
    "        muons = events.Muon\n",
    "        electrons = events.Electron\n",
    "        \n",
    "        ######\n",
    "        \n",
    "        # Select muons with pt >30, eta < 2.4, tight ID, and relIso < 0.15\n",
    "        muonSelectTight = ((muons.pt>30) &\n",
    "                           (abs(muons.eta)<2.4) &\n",
    "                           (muons.tightId) &\n",
    "                           (muons.pfRelIso04_all < 0.15)\n",
    "                          )\n",
    "\n",
    "        # Apply the selection to muons using the array[mask] syntax. \n",
    "        # tightMuons only includes the muons that pass the tight selection we defined\n",
    "        tightMuons = muons[muonSelectTight]\n",
    "        \n",
    "        ######\n",
    "        ### Step 2. Define your own selection for electrons. \n",
    "        ### Note that the ID variable names will be different. \n",
    "        ### Either remove the ID and iso variables or replace them with the correct electron values.\n",
    "        ######\n",
    "        \n",
    "        eleSelectTight = ((electrons.pt > 35) &\n",
    "                          (abs(electrons.eta) < 2.1) &\n",
    "                          ((abs(electrons.eta) < 1.4442) | (abs(electrons.eta) > 1.566)) &\n",
    "                          (electrons.cutBased >= 4)\n",
    "                         )\n",
    "        tightElectrons = electrons[eleSelectTight]\n",
    "\n",
    "        ######\n",
    "        \n",
    "        # Select events with exactly one tight muon. \n",
    "        eventSelectionMuon = (ak.num(tightMuons)==1)\n",
    "        \n",
    "        ######\n",
    "        ### Step 3. Define a second event selection requiring events with no muons and exactly one electron\n",
    "        ###### \n",
    "        eventSelectionEle = ((ak.num(tightElectrons)==1) & (ak.num(tightMuons)==0))\n",
    "\n",
    "        ######\n",
    "\n",
    "        # Fill the muon_pt histogram using the tightMuons in events that pass our selection \n",
    "        # Note that ak.flatten() is required when filling a histogram to remove the jaggedness\n",
    "        output['muon_pt'].fill(dataset=dataset,\n",
    "                              pt=ak.flatten(tightMuons[eventSelectionMuon].pt))\n",
    "        \n",
    "        ######\n",
    "        ### Step 4. Fill the ele_pt histogram you defined earlier\n",
    "        ###### \n",
    "        \n",
    "        output['ele_pt'].fill(dataset=dataset,\n",
    "                              pt=ak.flatten(tightElectrons[eventSelectionEle].pt))\n",
    "        \n",
    "        ######\n",
    "        \n",
    "        \n",
    "        \n",
    "        return {dataset: output}\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4ab877f1ad428890352b53f147f4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e632f8f622714519a7bbe89d2107dc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Exception",
     "evalue": "Failed processing file: WorkItem(dataset='TTbar', filename='root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/TTbar_1l.root', treename='Events', entrystart=0, entrystop=92405, fileuuid=b'\\x9bB\\xd2\\xd40\\xa9\\x11\\xea\\xb9qk\\xbd\\xe1\\x83\\xbe\\xef', usermeta={})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1640\u001b[0m, in \u001b[0;36mRunner._work_function\u001b[0;34m(format, xrootdtimeout, mmap, schema, cache_function, use_dataframes, savemetrics, item, processor_instance)\u001b[0m\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1640\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn [5], line 79\u001b[0m, in \u001b[0;36mTTGammaCutflow.process\u001b[0;34m(self, events)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Fill the muon_pt histogram using the tightMuons in events that pass our selection \u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Note that ak.flatten() is required when filling a histogram to remove the jaggedness\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmuon_pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtightMuons\u001b[49m\u001b[43m[\u001b[49m\u001b[43meventSelectionMuon\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m### Step 4. Fill the ele_pt histogram you defined earlier\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m###### \u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/hist/basehist.py:224\u001b[0m, in \u001b[0;36mBaseHist.fill\u001b[0;34m(self, weight, sample, threads, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03mInsert data into the histogram using names and indices, return\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03ma Hist object.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_to_index(k) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m k: v\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    227\u001b[0m }\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(data_dict) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/hist/basehist.py:225\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03mInsert data into the histogram using names and indices, return\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03ma Hist object.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m k: v\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    227\u001b[0m }\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(data_dict) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/hist/basehist.py:168\u001b[0m, in \u001b[0;36mBaseHist._name_to_index\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m index\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe axis name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The axis name dataset could not be found",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m fileset \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTTGamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/TTGamma_1l.root\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     ],\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run Coffea code using uproot\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_uproot_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTTGammaCutflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterative_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mNanoAODSchema\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/__init__.py:104\u001b[0m, in \u001b[0;36m_run_x_job\u001b[0;34m(fileset, treename, processor_instance, executor, executor_args, pre_executor, pre_args, chunksize, maxchunks, metadata_cache, dynamic_chunksize, format)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# make Runner instance, assume other args are for _work_function & co.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m run \u001b[38;5;241m=\u001b[39m Runner(\n\u001b[1;32m     95\u001b[0m     executor\u001b[38;5;241m=\u001b[39mexecutor,\n\u001b[1;32m     96\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexecutor_args,\n\u001b[1;32m    102\u001b[0m )\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1686\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, fileset, treename, processor_instance)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1666\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1667\u001b[0m     fileset: Dict,\n\u001b[1;32m   1668\u001b[0m     treename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1669\u001b[0m     processor_instance: ProcessorABC,\n\u001b[1;32m   1670\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Accumulatable:\n\u001b[1;32m   1671\u001b[0m     \u001b[38;5;124;03m\"\"\"Run the processor_instance on a given fileset\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m \n\u001b[1;32m   1673\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m            An instance of a class deriving from ProcessorABC\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1686\u001b[0m     wrapped_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dataframes:\n\u001b[1;32m   1688\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_out  \u001b[38;5;66;03m# not wrapped anymore\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1834\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, fileset, processor_instance, treename)\u001b[0m\n\u001b[1;32m   1829\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m   1830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_retries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipbadfiles, closure\n\u001b[1;32m   1831\u001b[0m )\n\u001b[1;32m   1833\u001b[0m executor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexe_args)\n\u001b[0;32m-> 1834\u001b[0m wrapped_out, e \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrapped_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1836\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1837\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo chunks returned results, verify ``processor`` instance structure.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;124m        if you used skipbadfiles=True, it is possible all your files are bad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1839\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:672\u001b[0m, in \u001b[0;36mIterativeExecutor.__call__\u001b[0;34m(self, items, function, accumulator)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rich_bar() \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[1;32m    668\u001b[0m     p_id \u001b[38;5;241m=\u001b[39m progress\u001b[38;5;241m.\u001b[39madd_task(\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesc, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(items), unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    670\u001b[0m     )\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 672\u001b[0m         \u001b[43maccumulate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m            \u001b[49m\u001b[43maccumulator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    680\u001b[0m         \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    681\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/accumulator.py:95\u001b[0m, in \u001b[0;36maccumulate\u001b[0;34m(items, accum)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m         accum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;66;03m# we want to produce a new object so that the input is not mutated\u001b[39;00m\n\u001b[1;32m     97\u001b[0m         accum \u001b[38;5;241m=\u001b[39m add(accum, \u001b[38;5;28mnext\u001b[39m(gen))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/accumulator.py:92\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccumulate\u001b[39m(\n\u001b[1;32m     90\u001b[0m     items: Iterable[Optional[Accumulatable]], accum: Optional[Accumulatable] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     91\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Accumulatable]:\n\u001b[0;32m---> 92\u001b[0m     gen \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m items \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m accum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/rich/progress.py:1221\u001b[0m, in \u001b[0;36mProgress.track\u001b[0;34m(self, sequence, total, task_id, description, update_period)\u001b[0m\n\u001b[1;32m   1219\u001b[0m advance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance\n\u001b[1;32m   1220\u001b[0m refresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh\n\u001b[0;32m-> 1221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m value\n\u001b[1;32m   1223\u001b[0m     advance(task_id, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1353\u001b[0m, in \u001b[0;36mRunner.automatic_retries\u001b[0;34m(retries, skipbadfiles, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m skipbadfiles\n\u001b[1;32m   1350\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuth failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chain)\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m retries \u001b[38;5;241m==\u001b[39m retry_count\n\u001b[1;32m   1352\u001b[0m     ):\n\u001b[0;32m-> 1353\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1354\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (retry_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1355\u001b[0m retry_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1337\u001b[0m, in \u001b[0;36mRunner.automatic_retries\u001b[0;34m(retries, skipbadfiles, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retry_count \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m retries:\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1337\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# catch xrootd errors and optionally skip\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;66;03m# or retry to read the file\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1642\u001b[0m, in \u001b[0;36mRunner._work_function\u001b[0;34m(format, xrootdtimeout, mmap, schema, cache_function, use_dataframes, savemetrics, item, processor_instance)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     out \u001b[38;5;241m=\u001b[39m processor_instance\u001b[38;5;241m.\u001b[39mprocess(events)\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed processing file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1645\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput of process() should not be None. Make sure your processor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms process() function returns an accumulator.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1646\u001b[0m     )\n",
      "\u001b[0;31mException\u001b[0m: Failed processing file: WorkItem(dataset='TTbar', filename='root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/TTbar_1l.root', treename='Events', entrystart=0, entrystop=92405, fileuuid=b'\\x9bB\\xd2\\xd40\\xa9\\x11\\xea\\xb9qk\\xbd\\xe1\\x83\\xbe\\xef', usermeta={})"
     ]
    }
   ],
   "source": [
    "# Define files to run over\n",
    "fileset = {\n",
    "    \"TTGamma\": [\n",
    "        \"root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/TTGamma_1l.root\"\n",
    "    ],\n",
    "    \"TTbar\": [\n",
    "        \"root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/TTbar_1l.root\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Run Coffea code using uproot\n",
    "output = processor.run_uproot_job(\n",
    "    fileset,\n",
    "    \"Events\",\n",
    "    TTGammaCutflow(),\n",
    "    processor.iterative_executor,\n",
    "    {\"schema\": NanoAODSchema},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(5, 8))\n",
    "# Plot the muon_pt histogram, overlaying the distribution for each dataset\n",
    "# Sometimes have to run this cell twice for the plot to appear\n",
    "output['TTGamma']['muon_pt'].plot1d(ax=ax1, label='ttgamma');\n",
    "output['TTbar']['muon_pt'].plot1d(ax=ax1, label='ttbar');\n",
    "plt.legend();\n",
    "\n",
    "######\n",
    "### Step 5. Plot the ele_pt histogram\n",
    "###### \n",
    "output['TTGamma']['ele_pt'].plot1d(ax=ax2, label='ttgamma');\n",
    "output['TTbar']['ele_pt'].plot1d(ax=ax2, label='ttbar');\n",
    "plt.legend();\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to look at other files, feel free to edit _fileset_ above using the skimmed datasets here: /store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['TTGamma']['muon_pt'].plot1d(density=True, label='ttgamma');\n",
    "output['TTbar']['muon_pt'].plot1d(density=True, label='ttbar');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['TTGamma']['ele_pt'].plot1d(density=True, label='ttgamma');\n",
    "output['TTbar']['ele_pt'].plot1d(density=True, label='ttbar');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've seen some of the basics of histogramming, object cuts, and event selection, let's go through how to apply weights to the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from coffea.lookup_tools import dense_lookup\n",
    "from coffea.analysis_tools import Weights\n",
    "\n",
    "class TTGammaWeights(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # There are several utilities within coffea that can help us apply weights and systematics to the code\n",
    "        # We use uproot to open the root file containing the electron ID scale factors:\n",
    "        ele_id_file = uproot.open('ttgamma/scalefactors/MuEGammaScaleFactors/ele2016/2016LegacyReReco_ElectronTight_Fall17V2.root')\n",
    "        # The dense_lookup tools in Coffea make it easy to extract the histogram (named EGamma_SF2D in this case)\n",
    "        # with the weights and their errors:\n",
    "        self.ele_id_sf = dense_lookup.dense_lookup(\n",
    "            ele_id_file[\"EGamma_SF2D\"].values(),\n",
    "            (\n",
    "                ele_id_file[\"EGamma_SF2D\"].axis(0).edges(),\n",
    "                ele_id_file[\"EGamma_SF2D\"].axis(1).edges()\n",
    "            )\n",
    "        )\n",
    "        self.ele_id_err = dense_lookup.dense_lookup(\n",
    "            ele_id_file[\"EGamma_SF2D\"].variances()**0.5,\n",
    "            (\n",
    "                ele_id_file[\"EGamma_SF2D\"].axis(0).edges(),\n",
    "                ele_id_file[\"EGamma_SF2D\"].axis(1).edges()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dataset_axis = hist.axis.StrCategory([], name=\"dataset\", label=\"Dataset\", growth=True)\n",
    "\n",
    "        # The systematic axis will be used to keep track of whether we are using the nominal weights\n",
    "        # or the weights shifted up/down by their errors\n",
    "        systematic_axis = hist.axis.StrCategory([], name=\"systematic\", label=\"Systematic uncertainty\", growth=True)\n",
    "        \n",
    "        ele_pt_axis  = hist.axis.Regular(40, 0, 200, name=\"pt\", label=\"Electron $p_{T}$ [GeV]\")\n",
    "\n",
    "        self.make_output = lambda: {\n",
    "            'ele_pt' : hist.Hist(dataset_axis, systematic_axis, ele_pt_axis),\n",
    "        }\n",
    "\n",
    "    def process(self, events):\n",
    "\n",
    "        output = self.make_output()\n",
    "\n",
    "        dataset = events.metadata['dataset']\n",
    "\n",
    "        electrons = events.Electron\n",
    "        \n",
    "        #Define tight electron selection\n",
    "        electronSelectTight = (\n",
    "            (electrons.pt>35) & \n",
    "            (abs(electrons.eta)<2.1) & \n",
    "            ((abs(electrons.eta) < 1.4442) | (abs(electrons.eta) > 1.566)) &      \n",
    "            (electrons.cutBased>=4)\n",
    "        )\n",
    "        # Apply selection\n",
    "        tightElectron = electrons[electronSelectTight]\n",
    "        #Define event selection\n",
    "        eventSelection = (ak.num(tightElectron) == 1)\n",
    "\n",
    "\n",
    "        # Here, we look up the scale factors and errors for each electron using the electron eta and pt\n",
    "        eleID = self.ele_id_sf(tightElectron.eta, tightElectron.pt)\n",
    "        eleIDerr = self.ele_id_err(tightElectron.eta, tightElectron.pt)\n",
    "        \n",
    "        #To get an event-level weight, multiply the SF for each electron in the event\n",
    "            # SF : scale factor\n",
    "        #The axis=-1 option means we are multiplying the innermost values (electrons per event in this case)\n",
    "        eleSF = ak.prod(eleID, axis=-1) # product of elements along axis\n",
    "        eleSFUp = ak.prod(eleID+eleIDerr, axis=-1)\n",
    "        eleSFDown = ak.prod(eleID-eleIDerr, axis=-1)\n",
    "        print(eleSF, eleSFUp, eleSFDown)\n",
    "    \n",
    "        # The Weights object is a container that handles the bookkeeping \n",
    "        # for event weights and associated systematic shifts.\n",
    "        # The argument for the Weights object is the number of events we are processing\n",
    "        weights = Weights(len(events))\n",
    "\n",
    "        # Add the ele ID SF to the weights object\n",
    "        weights.add('eleEffWeight',weight=eleSF,weightUp=eleSFUp,weightDown=eleSFDown)\n",
    "        \n",
    "        systList = ['noweight','nominal','eleEffWeightUp','eleEffWeightDown']\n",
    "\n",
    "        for syst in systList:\n",
    "           \n",
    "            weightSyst = syst\n",
    "            if syst=='nominal':\n",
    "                weightSyst=None\n",
    "                \n",
    "            if syst=='noweight':\n",
    "                evtWeight = np.ones(len(events))\n",
    "            else:\n",
    "                evtWeight = weights.weight(weightSyst) # overall event weight\n",
    "                \n",
    "            output['ele_pt'].fill(\n",
    "                systematic=syst,\n",
    "                pt=ak.flatten(tightElectron[eventSelection].pt),\n",
    "                weight=evtWeight[eventSelection]\n",
    "            )\n",
    "           \n",
    "        return {dataset: output}\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define files to run over\n",
    "fileset = {\n",
    "    \"TTGamma\": [\n",
    "        \"root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/TTGamma_1l.root\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Run Coffea code using uproot\n",
    "output = processor.run_uproot_job(\n",
    "    fileset,\n",
    "    \"Events\",\n",
    "    TTGammaWeights(),\n",
    "    processor.iterative_executor,\n",
    "    {\"schema\": NanoAODSchema},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pt distributions for each of the different systematics\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "output['TTGamma']['ele_pt'].plot1d(overlay='systematic', label=['eleEffWeightDown','eleEffWeightUp','nominal','noWeight']);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.prod([[1,2,3],[4,5]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.prod([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ttgamma.scalefactors as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.ele_id_sf # same as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTGammaWeights().ele_id_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
